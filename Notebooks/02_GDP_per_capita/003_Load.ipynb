{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9288713b-7967-4c56-8cf9-9a98bacd3444",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importa o módulo de funções do PySpark para manipulação de colunas e dados\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "214fa3d9-48d7-4f58-ab94-7742d86166ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define o fuso horário da sessão Spark para \"America/Sao_Paulo\"\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"America/Sao_Paulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b071ec78-4b15-41b9-b09a-5d29243a746e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Caminho da tabela Delta de origem no nível 'silver' do pipeline de dados\n",
    "origem_path = \"fomacao_microsoft_power_bi_profisional.silver.fato_vendas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0fea0c4-3c26-4a1e-b2f1-819d40cb9ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lê a tabela Delta de origem e seleciona colunas relevantes para o DataFrame 'df_gold'\n",
    "df_gold = (spark.read.table(origem_path)\n",
    "           .select(\n",
    "                 \"ProductID\"      # Identificador do produto\n",
    "               , \"Date\"           # Data da venda\n",
    "               , \"Zip\"            # Código postal\n",
    "               , \"Units\"          # Quantidade vendida\n",
    "               , \"Revenue\"        # Receita gerada\n",
    "               , \"Country\"        # País da venda\n",
    "               , \"_ingest_ts_utc\" # Timestamp de ingestão em UTC\n",
    "               , \"_ingest_date\"   # Data de ingestão\n",
    "               )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce02fea-75ad-4b5b-a214-64be278241d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Nome da tabela de destino no nível 'gold' do pipeline de dados\n",
    "tbl = 'fato_vendas'\n",
    "destino_path = f'fomacao_microsoft_power_bi_profisional.gold.{tbl}'\n",
    "\n",
    "# Escreve o DataFrame 'df_gold' como uma tabela Delta particionada por '_ingest_date'\n",
    "df_gold = (df_gold.write\n",
    "             .format('delta')                # Formato Delta Lake\n",
    "             .mode('overwrite')              # Sobrescreve dados existentes\n",
    "             .option('overwriteSchema', 'true') # Sobrescreve o schema se necessário\n",
    "             .partitionBy('_ingest_date')    # Particiona por data de ingestão\n",
    "             .saveAsTable(destino_path))     # Salva como tabela Delta\n",
    "\n",
    "# Exibe a contagem de registros da tabela de destino\n",
    "print(f'Contagem de registros: {spark.table(destino_path).count()}')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "003_Load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
